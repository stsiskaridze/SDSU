{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**CS596 - Machine Learning**\n",
    "<br>\n",
    "Date: **4 October 2020**\n",
    "<br>\n",
    "Title: **Midterm 1 - Preparation**\n",
    "\n",
    "The exam will be evaluated at a maximum 20 points. Each problem is 5 points. Each subtask is 1 point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Part 1: 5 October 2020</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align=\"center\">Problem Type 1A: Matrix Norms</h3>\n",
    "\n",
    "Let's consider the matrix from the **Problem №4** of the **Homework №1**:\n",
    "\n",
    "$$A = \\begin{bmatrix}\n",
    "2 & -1 &  0\\\\ \n",
    "-1 & 1 & 1 \\\\\n",
    "0 & 1 & 2 \n",
    "\\end{bmatrix}.$$\n",
    "\n",
    "Calculate the following norms:\n",
    "1. $\\left \\| A \\right \\|_1$\n",
    "2. $\\left \\| A \\right \\|_\\infty$\n",
    "3. $\\left \\| A \\right \\|_{sum}$\n",
    "4. $\\left \\| A \\right \\|_{F}$\n",
    "5. $\\left \\| A \\right \\|_{*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align=\"center\">Problem Type 1B: The Multi-Class Cofusion Matrix</h3>\n",
    "\n",
    "- Given a **confusion matrix** for some classifier:\n",
    "\n",
    "  <img src=\"images/H1_CM3.png\" width=\"300\" alt=\"Example\" />\n",
    "\n",
    "\n",
    "- Calculate the following **metrics**:\n",
    "  1. The number of **True Positive** predictions (**overall**);\n",
    "  2. The number of **False Positive** predictions for **class A**.\n",
    "  3. The **True Positive Rate** for the **class A**.\n",
    "  4. **Precision** for the **class A**.\n",
    "  5. **Accuracy** of the classifier.\n",
    "  \n",
    "  \n",
    "- **Hint**:  Usefull links for this material:\n",
    "\n",
    "  https://dev.to/overrideveloper/understanding-the-confusion-matrix-264i\n",
    "\n",
    "  https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "\n",
    "  https://sdsu.instructure.com/files/505240/download?download_frd=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align=\"center\">Problem Type 2A: Naive Bayes Classifier</h3>\n",
    "\n",
    "Suppose we want to build a classifier that says whether a text is about sports or not.\n",
    "\n",
    "|            **Text**            | **Tag** |\n",
    "|:-------------------------------|:----------:|\n",
    "| “A great game”                 | Sports        |\n",
    "| “The election was over”        | Not Sports    |\n",
    "| “Very clean match”             | Sports        |\n",
    "| “A clean but forgettable game” | Sports        |\n",
    "| “It was a close election”      | Not Sports        |\n",
    "\n",
    "Suppose we have: \n",
    "- $B : \\{ \\text{Text = \"A very close game\"}\\}$;\n",
    "- $A : \\{ \\text{Tag = Sports}\\}$;\n",
    "What is the probability $P(A|B)$?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Perform the next steps:\n",
    "\n",
    "1. Define the subsets $B_i$: $B = B_1 \\cup  B_2 \\cup \\cdots  \\cup  B_n$ and $A$;\n",
    "2. Calculate the individual probabilities with respect to each feature of interest;\n",
    "3. Apply **Laplace smoothing** if needed;\n",
    "4. Calculate the total probability for $A$ and $\\overline{A}$;\n",
    "5. Obtain the final probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3 align=\"center\">Solution of Problem 2A</h3>\n",
    "\n",
    "0. Remember the Extended Naive Bayes's theorem:\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B| \\overline{A})P(\\overline{A})};$$\n",
    "$$P(B|A) = P(B_1|A)\\times P(B_2|A)\\times P(B_3|A)\\times P(B_4|A)$$ \n",
    "$$P(B|\\overline{A}) = P(B_1|\\overline{A})\\times P(B_2|\\overline{A})\\times P(B_3|\\overline{A})\\times P(B_4|\\overline{A}).$$\n",
    "\n",
    "1. Define the subsets $B_i$: $B = B_1 \\cup  B_2 \\cup  B_3 \\cup  B_4$, where:\n",
    "\n",
    " - $B_1 : \\{ \\text{Text = \"A \"}\\}$;\n",
    " - $B_2 : \\{ \\text{Text = \"very\"}\\}$;\n",
    " - $B_3 : \\{ \\text{Text = \"close\"}\\}$;\n",
    " - $B_4 : \\{ \\text{Text = \"game\"}\\}$;\n",
    "\n",
    "2. Calculate the individual probabilities with respect to each feature of interest:\n",
    "\n",
    "|     Word    | Sports | Not Sports | P(Sports)         | P(Not Sports)         |\n",
    "|:-----------:|:---:|----|----------------|---------------|\n",
    "| a           |  2  |  1 | $\\frac{2}{11}$ | $\\frac{1}{9}$ |\n",
    "| great       |  1  |  0 |                |               |\n",
    "| very        |  1  |  0 | $\\frac{1}{11}$ | $\\frac{0}{9}$ |\n",
    "| over        |  0  |  1 |                |               |\n",
    "| it          |  0  |  1 |                |               |\n",
    "| but         |  1  |  0 |                |               |\n",
    "| game        |  2  |  0 | $\\frac{2}{11}$ | $\\frac{0}{9}$ |\n",
    "| election    |  0  |  2 |                |               |\n",
    "| clean       |  2  |  0 |                |               |\n",
    "| close       |  0  |  1 | $\\frac{0}{11}$ | $\\frac{1}{9}$ |\n",
    "| the         |  0  |  1 |                |               |\n",
    "| was         |  0  |  2 |                |               |\n",
    "| forgettable |  1  |  0 |                |               |\n",
    "| match       |  1  |  0 |                |               |\n",
    "| Total       |  11 |  9 |                |               |\n",
    "\n",
    "&emsp; &ensp; We run into a problem here: **“close” doesn’t appear in any Sports text**: \n",
    "<br> &emsp; &ensp; since in a multiplication **if one of the terms is zero**, the **whole probability is nullified**.\n",
    "\n",
    "3. Apply so called **Laplace smoothing**: we add $1$ to every count so it’s never zero:\n",
    "\n",
    "|     Word    | Sports | Not Sports | P(Sports)         | P(Not Sports)         |\n",
    "|:-----------:|:---:|----|----------------|---------------|\n",
    "| **a**       |  3  |  2 | $\\frac{3}{25}$ | $\\frac{2}{23}$ |\n",
    "| great       |  2  |  1 | $\\frac{2}{25}$ | $\\frac{1}{23}$ |\n",
    "| **very**    |  2  |  1 | $\\frac{2}{25}$ | $\\frac{1}{23}$ |\n",
    "| over        |  1  |  2 | $\\frac{1}{25}$ | $\\frac{2}{23}$ |\n",
    "| it          |  1  |  2 | $\\frac{1}{25}$ | $\\frac{2}{23}$ |\n",
    "| but         |  2  |  1 | $\\frac{2}{25}$ | $\\frac{1}{23}$ |\n",
    "| **game**    |  3  |  1 | $\\frac{3}{25}$ | $\\frac{1}{23}$ |\n",
    "| election    |  1  |  3 | $\\frac{1}{25}$ | $\\frac{3}{23}$ |\n",
    "| clean       |  3  |  1 | $\\frac{3}{25}$ | $\\frac{1}{23}$ |\n",
    "| **close**   |  1  |  2 | $\\frac{1}{25}$ | $\\frac{2}{23}$ |\n",
    "| the         |  1  |  2 | $\\frac{1}{25}$ | $\\frac{2}{23}$ |\n",
    "| was         |  1  |  3 | $\\frac{1}{25}$ | $\\frac{3}{23}$ |\n",
    "| forgettable |  2  |  1 | $\\frac{2}{25}$ | $\\frac{1}{23}$ |\n",
    "| match       |  2  |  1 | $\\frac{2}{25}$ | $\\frac{1}{23}$ |\n",
    "| Total       |  25 | 23 | 1 | 1 |\n",
    "\n",
    "4. Calculate the total probability for $A$ and $\\overline{A}$:\n",
    "\n",
    "|          | Tag    | Probability      |\n",
    "|:---------|:------:|:----------------:|\n",
    "| Sports   |   25   | $\\frac{25}{48}$  |\n",
    "|Not Sports|  23    | $\\frac{23}{48}$  |\n",
    "| Total    |   48   | 1                |\n",
    "\n",
    "\n",
    "5. Now we just multiply all the probabilities and obtain the result:\n",
    "\n",
    "$$P(A|B) = \\frac{ \\frac{3}{25} \\cdot \\frac{2}{25} \\cdot \\frac{3}{25} \\cdot \\frac{1}{25} \\cdot \\frac{25}{48} }\n",
    "{\\frac{3}{25} \\cdot \\frac{2}{25} \\cdot \\frac{3}{25} \\cdot \\frac{1}{25} \\frac{25}{48} + \n",
    " \\frac{2}{23} \\cdot \\frac{1}{23} \\cdot \\frac{1}{23} \\cdot \\frac{2}{23} \\frac{23}{48} } = 0.78$$\n",
    "\n",
    "&emsp; &ensp; Excellent! Our classifier gives “**A very close game**” the **Sports** tag with **78% probability**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7779798654380369"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( 3/25 * 2/25 * 3/25 * 1/25 * 25/48 ) / ( 3/25 * 2/25 * 3/25 * 1/25 * 25/48 + 2/23 * 1/23 * 1/23 * 2/23 * 23/48 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align=\"center\">Problem Type 2B: Decision Tree</h3>\n",
    "\n",
    "- Problem will consist of classification problem which solution follows closely the Decision Tree algorithm described here:\n",
    "\n",
    "  https://medium.com/datadriveninvestor/decision-tree-algorithm-with-hands-on-example-e6c2afb40d38\n",
    "\n",
    "\n",
    "- Given the **symptoms** and **diagnoses** of several examined patients:\n",
    "\n",
    "| Fever | Chills | Headache | Flu? |\n",
    "|:-----:|:------:|:--------:|:----:|\n",
    "|  Yes  |   Yes  |   Mild   |  No  |\n",
    "|   No  |   Yes  |   Week   |  Yes |\n",
    "|  Yes  |   Yes  |  Strong  |  Yes |\n",
    "|  Yes  |   No   |   Mild   |  Yes |\n",
    "|   No  |   No   |   Week   |  No  |\n",
    "|  Yes  |   No   |  Strong  |  Yes |\n",
    "|   No  |   No   |  Strong  |  No  |\n",
    "\n",
    "- **Problem Statement**:\n",
    "\n",
    "  Build **decision tree** using **CART** or **ID3** algorithm for classification:\n",
    "  1. **Find** the **entropy** of class variable;\n",
    "  2. **Calculate** the **avarage weighted entropy** for each feature;\n",
    "  3. **Find** the **information gain** for each feature;\n",
    "  4. **Select** the **feature** having the **largest entropy gain** and **split** the **data table**.\n",
    "  5. **Repeat** the steps and  **find the next (all) nodes** in for the decision tree.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Ent(x, y):\n",
    "    if x == 0 or y == 0:\n",
    "        z = 0\n",
    "    else:\n",
    "        z = -( x / (x + y) * np.log2(x / (x + y)) + y / (x + y) * np.log2(y / (x + y)))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852281360342515"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = 4\n",
    "N = 3\n",
    "T = Y + N\n",
    "\n",
    "E_S =  - ( Y/T * np.log2(Y/T) + N/T * np.log2(N/T) )\n",
    "E_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY = 3\n",
    "YN = 1\n",
    "NY = 1\n",
    "NN = 2\n",
    "\n",
    "YA = YY + YN\n",
    "NA = NY + NN\n",
    "TA = YA + NA\n",
    "\n",
    "E_SA =  YA/TA * Ent(YY, YN) + NA/TA * Ent(NY, NN)\n",
    "E_SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12808527889139443"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IG = E_S - E_SA\n",
    "IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649839288804954"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY = 2\n",
    "YN = 1\n",
    "NY = 2\n",
    "NN = 2\n",
    "\n",
    "YA = YY + YN\n",
    "NA = NY + NN\n",
    "TA = YA + NA\n",
    "\n",
    "E_SA =  YA/TA * Ent(YY, YN) + NA/TA * Ent(NY, NN)\n",
    "E_SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020244207153756077"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IG = E_S - E_SA\n",
    "IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "WY = 1\n",
    "WN = 1\n",
    "MY = 1\n",
    "MN = 1\n",
    "SY = 2\n",
    "SN = 1\n",
    "\n",
    "WA = WY + WN\n",
    "MA = MY + MN\n",
    "SA = SY + SN\n",
    "TA = WA + MA + SA\n",
    "\n",
    "E_SA =  WA/TA * Ent(WY, WN) + MA/TA * Ent(MY, MN) + SA/TA * Ent(SY, SN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020244207153756077"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IG = E_S - E_SA\n",
    "IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8112781244591328"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = 3\n",
    "N = 1\n",
    "T = Y + N\n",
    "\n",
    "E_S =  - ( Y/T * np.log2(Y/T) + N/T * np.log2(N/T) )\n",
    "E_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY = 1\n",
    "YN = 1\n",
    "NY = 2\n",
    "NN = 0\n",
    "\n",
    "YA = YY + YN\n",
    "NA = NY + NN\n",
    "TA = YA + NA\n",
    "\n",
    "E_SA =  YA/TA * Ent(YY, YN) + NA/TA * Ent(NY, NN)\n",
    "E_SA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Part 2: 7 October 2020</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second Part of the Midterm Exam 1 will be related with:\n",
    "  - EDA (Seminar 4a)\n",
    "  - Data Preprocessing (Seminar 2, 4b)\n",
    "  - Fitting the model:\n",
    "      - Linear Regression (Seminar 1, 2)\n",
    "      - Logistic Regression (Seminar 4a)\n",
    "      - Gaussian Naive Bayes (Seminar 4b)\n",
    "      - Nearest neighbour method (Seminar 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">I wish you good luck on the exam</h1>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
