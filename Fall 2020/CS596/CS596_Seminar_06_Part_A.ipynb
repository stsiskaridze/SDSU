{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**CS596 - Machine Learning**\n",
    "<br>\n",
    "Date: **19 October 2020**\n",
    "\n",
    "\n",
    "Title: **Seminar 5 - Part A**\n",
    "<br>\n",
    "Speaker: **Dr. Shota Tsiskaridze**\n",
    "<br>\n",
    "Teaching Assistant: **Levan Sanadiradze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\">Decision Tree Classifier</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Diabetes** is a chronic condition in which the **body develops a resistance to insulin**, a hormone which converts food into glucose. \n",
    "\n",
    "\n",
    "- **Diabetes affect many people worldwide** and is normally divided into **Type 1** and **Type 2** diabetes. **Both** have **different characteristics**. \n",
    "\n",
    "\n",
    "- We **are going to build a model** on the **PIMA Indian Diabetes dataset** to **predict if a particular observation is at a risk of developing diabetes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import google colab library for loading dataset files\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "\n",
    "# Load cvs dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"diabetes.csv\", header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "\n",
    "# Define feature variable\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Define target variable\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train decision tree model\n",
    "model = model.fit(X_train,y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model Accuracy\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thus, we've got a classification rate of 67.53%, considered as **good accuracy**. \n",
    "\n",
    "\n",
    "- However, **we can improve** this **accuracy** by **tuning the parameters** in the Decision Tree Algorithm.\n",
    "\n",
    "\n",
    "- We can use Scikit-learn's **export_graphviz** function for display the tree within a Jupyter notebook. \n",
    "\n",
    "\n",
    "- For plotting tree, you also need to **install graphviz** and **pydotplus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing Decision Trees\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('diabetes.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the **decision tree chart**, each internal node has a **decision rule** that splits the data. \n",
    "\n",
    "\n",
    "- **Gini** referred as **Gini ratio**, which measures the impurity of the node. \n",
    "\n",
    "\n",
    "- We say that a **node is pure** when **all of its records belong to the same class**, such nodes known as the **leaf node**.\n",
    "\n",
    "\n",
    "- Here, the resultant **tree is unpruned**. This unpruned tree is unexplainable and not easy to understand. Let's **optimize** it by **pruning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\">Optimizing Decision Tree Performance</h2>\n",
    "\n",
    "- In Scikit-learn, **optimization** of decision tree classifier **performed** by only **pre-pruning**. \n",
    "\n",
    "\n",
    "- **Maximum depth** of the tree **can be used** as a **control variable** for pre-pruning. \n",
    "\n",
    "\n",
    "- Let's plot a decision tree on the same data with `max_depth = 3` and selection `criterion = \"entropy\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build decision tree model\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train decision tree model\n",
    "model = model.fit(X_train,y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Well, the **classification rate** increased to **77.05%**, which is **better accuracy** than the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Decision Trees\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, feature_names = feature_cols,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('diabetes.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This **pruned model** is less complex, explainable, and **easy to understand** than the previous decision tree model plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align=\"center\">Conclusions</h2>\n",
    "\n",
    "- Advantages:\n",
    "  - Decision trees are **easy to interpret** and **visualize**.\n",
    "  - It can easily **capture Non-linear patterns**.\n",
    "  - It requires **fewer data preprocessing** from the user, for example, there is no need to normalize columns.\n",
    "  - It can be **used for feature engineering** such as **predicting missing values**, suitable for variable selection.\n",
    "  - The decision tree **has no assumptions about distribution** because of the non-parametric nature of the algorithm. \n",
    "  \n",
    "\n",
    "- Disadvantages:\n",
    "  - **Sensitive to noisy data**. It can overfit noisy data.\n",
    "  - The **small variation** (or **variance**) in data can **result** in the **different decision tree**. This **can be reduced** by **bagging** and **boosting**.\n",
    "  - Decision trees are **biased with imbalance dataset**, so it is **recommended** to **balance out the dataset before building the decision tree**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">End of Part A</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
